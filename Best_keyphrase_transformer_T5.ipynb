{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoPXwPaYZ563FC6xzgcr/1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahimku2020/fahimku2020/blob/main/Best_keyphrase_transformer_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MYw2cGjXHaqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keyphrasetransformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXCs6ejPVgQf",
        "outputId": "67133b2e-52d4-4b24-ba13-d3a8ec45c2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keyphrasetransformer\n",
            "  Downloading keyphrasetransformer-0.0.2.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from keyphrasetransformer) (3.9.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from keyphrasetransformer) (4.47.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->keyphrasetransformer) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->keyphrasetransformer) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->keyphrasetransformer) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->keyphrasetransformer) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->keyphrasetransformer) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers->keyphrasetransformer) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->keyphrasetransformer) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->keyphrasetransformer) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->keyphrasetransformer) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->keyphrasetransformer) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->keyphrasetransformer) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->keyphrasetransformer) (0.4.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers->keyphrasetransformer) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers->keyphrasetransformer) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->keyphrasetransformer) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->keyphrasetransformer) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->keyphrasetransformer) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->keyphrasetransformer) (2024.12.14)\n",
            "Building wheels for collected packages: keyphrasetransformer\n",
            "  Building wheel for keyphrasetransformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keyphrasetransformer: filename=keyphrasetransformer-0.0.2-py3-none-any.whl size=4180 sha256=d926aec2682ed3798529d6759170d898034ab152d6b50fc70f5f199780a4f1c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/84/70/8a043e66f4f5dd346129170b3729f80985226b4aace0f2795b\n",
            "Successfully built keyphrasetransformer\n",
            "Installing collected packages: keyphrasetransformer\n",
            "Successfully installed keyphrasetransformer-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnIEXljRYg_O",
        "outputId": "0ad85c3c-922b-4809-af66-079a6327a642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KvW7IjBZYgds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from keyphrasetransformer import KeyPhraseTransformer\n",
        "\n",
        "kp = KeyPhraseTransformer()\n",
        "\n",
        "doc = \"\"\"\n",
        "\n",
        "\n",
        "Imran Ahmed Khan Niazi[a] (born 5 October 1952) is a Pakistani politician and former cricketer who served as the 19th prime minister of Pakistan from August 2018 until April 2022. He is the founder and former chairman of the political party Pakistan Tehreek-e-Insaf (PTI) from 1996 to 2023. He was the captain of the Pakistan national cricket team throughout the 1980s and early 1990s.\n",
        "Born in Lahore, Khan graduated from Keble College, Oxford. He began his international cricket career in a 1971 Test series against England. Khan played until 1992, served as the team's captain intermittently between 1982 and 1992, and won the 1992 Cricket World Cup, Pakistan's only victory in the competition. Considered one of cricket's greatest all-rounders, Khan was later inducted into the ICC Cricket Hall of Fame.\n",
        "\n",
        "Founding the Pakistan Tehreek-e-Insaf (PTI) in 1996, Khan won a seat in the National Assembly from his hometown of Mianwali, in the 2002 general election. PTI became the second-largest party by popular vote in the 2013 election, and five years later, running on a populist platform, PTI formed a coalition government with independents with Khan as prime minister. Khan's government addressed a balance of payments crisis with bailouts from the IMF. Limiting defence spending, he presided over a shrinking current account deficit, leading to some general economic growth, helped by policies increasing tax collection and investment. His government advocated for transforming Pakistan into a welfare state, committed to a renewable energy transition, launched Ehsaas Programme and the Plant for Pakistan initiative, and expanded the protected areas of Pakistan. He presided over the COVID-19 pandemic, which caused economic turmoil and rising inflation in the country. In April 2022, during a constitutional crisis following the Lettergate affair, Khan became the first Pakistani prime minister to be removed from office through a no-confidence motion.\n",
        "\n",
        "In October that year, on account of the Toshakhana reference case, Khan was disqualified by the Election Commission of Pakistan from taking office for one term of the National Assembly of Pakistan. In November, he survived an assassination attempt during a political rally in Wazirabad. In May 2023, Khan was arrested on corruption charges at the Islamabad High Court by paramilitary troops. Protests broke out throughout Pakistan, some of which escalated into violent riots. Khan was sentenced to a three-year jail term in August 2023 after being found guilty of misusing his premiership to buy and sell gifts in state possession. He was subsequently sentenced to ten years in prison in early 2024 for leaking state secrets and violating the Official Secrets Act in the Lettergate affair, and an additional seven years for breaching Islamic marriage laws with his wife; both of these sentences were overturned in mid-2024. Khan has since been charged on matters related to the 2023 riots and clashes between his supporters and police in September 2024.\n",
        "\n",
        "Khan made his debut at the age of 16 in Lahore. By the start of the 1970s, he was playing for his home teams of Lahore A (1969–1970), Lahore B (1969–1970), Lahore Greens (1970–1971), and eventually Lahore (1970–1971).[66] Khan was part of the University of Oxford's Blues Cricket team during the 1973–1975 seasons.[23] Khan played English county cricket from 1971 to 1976 for Worcestershire. During this decade, other teams represented by Khan included Dawood Industries (1975–1976) and Pakistan International Airlines (1975–1976, 1980–1981). From 1983 to 1988, he played for Sussex.[67]\n",
        "\n",
        "\n",
        "Khan's bowling statistics as a cricketer from 1971 to 1991.\n",
        "Khan made his Test cricket debut against England in June 1971 at Edgbaston.[68] Three years later, in August 1974, he debuted in the One Day International (ODI) match, once again playing against England at Trent Bridge for the Prudential Trophy.[68] After graduating from Oxford and finishing his tenure at Worcestershire, he returned to Pakistan in 1976 and secured a permanent place on his native national team starting from the 1976–1977 season, during which they faced New Zealand and Australia.[66] Following the Australian series, he toured the West Indies, where he met Tony Greig, who signed him up for Kerry Packer's World Series Cricket.[67] His credentials as one of the fastest bowlers in the world started to become established when he finished third at 139.7 km/h in a fast bowling contest at Perth in 1978, behind Jeff Thomson and Michael Holding but ahead of Dennis Lillee, Garth Le Roux, and Andy Roberts.[69] During the late 1970s, Khan was one of the pioneers of the reverse swing bowling technique.[70] He imparted this trick to the bowling duo of Wasim Akram and Waqar Younis, who mastered and popularised this art in later years.[71]\n",
        "\n",
        "As a bowler, Khan initially bowled with a relatively chest-on action, at medium-pace;[72] however, he worked hard to remodel his action to a more classical type, and to strengthen his body, to enable fast bowling.[73][74] Khan attained his prime as a fast bowler in January 1980 till 1988 when he became out and out fast bowler. During this span Imran picked 236 test wickets at 17.77 apiece with 18 five-wicket hauls and 5 10 wicket hauls. His bowling average and strike rate were better than Richard Hadlee (19.03), Malcolm Marshall (20.20), Dennis Lillee (24.07), Joel Garner (20.62), and Michael Holding (23.68).[75][76] In January 1983, playing against India, he attained a Test bowling rating of 922 points. Although calculated retrospectively (International Cricket Council (ICC) player ratings did not exist at the time), Khan's form and performance during this period ranks third in the ICC's All-Time Test Bowling Rankings.[77]\n",
        "\n",
        "Khan achieved the all-rounder's triple (securing 3000 runs and 300 wickets) in 75 Tests, the second-fastest record behind Ian Botham's 72. He also has the second-highest all-time batting average of 61.86 for a Test batsman playing at position 6 in the batting order.[78] He played his last Test match for Pakistan in January 1992, against Sri Lanka at Faisalabad. Khan retired permanently from cricket six months after his last ODI, the historic 1992 Cricket World Cup Final against England in Melbourne, Australia.[79] He ended his career with 88 Test matches, 126 innings and scored 3807 runs at an average of 37.69, including six centuries and 18 fifties. His highest score was 136. As a bowler, he took 362 wickets in Test cricket, which made him the first Pakistani and world's fourth bowler to do so.[67] In ODIs, he played 175 matches and scored 3709 runs at an average of 33.41. His highest score was 102 not out. His best ODI bowling was 6 wickets for 14 runs, a record for the best bowling figures by any bowler in an ODI innings in a losing cause.[80]\n",
        "\n",
        "Captaincy\n",
        "At the height of his career, in 1982,[81] the thirty-year-old Khan took over the captaincy of the Pakistan cricket team from Javed Miandad.[82] As a captain, Khan played 48 Test matches, of which 14 were won by Pakistan, 8 lost and the remaining 26 were drawn. He also played 139 ODIs, winning 77, losing 57 and ending one in a tie.[67]\n",
        "\n",
        "In the team's second match, Khan led them to their first Test win on English soil for 28 years at Lord's.[83] Khan's first year as captain was the peak of his legacy as a fast bowler as well as an all-rounder. He recorded the best Test bowling of his career while taking 8 wickets for 58 runs against Sri Lanka at Lahore in 1981–1982.[67] He also topped both the bowling and batting averages against England in three-Test series in 1982, taking 21 wickets and averaging 56 with the bat. Later the same year, he put up a highly acknowledged performance in a home series against the formidable Indian team by taking 40 wickets in six Tests at an average of 13.95. By the end of this series in 1982–1983, Khan had taken 88 wickets in 13 Test matches over a period of one year as captain.[66] This same Test series against India also resulted in a stress fracture in his shin that kept him out of cricket for more than two years. An experimental treatment funded by the Pakistani government helped him recover by the end of 1984 and he made a successful comeback to international cricket in the latter part of the 1984–1985 season.[67]\n",
        "\n",
        "In 1987 in India, Khan led Pakistan in its first-ever Test series win and this was followed by Pakistan's first series victory in England during the same year.[83] During the 1980s, his team also recorded three creditable draws against the West Indies. India and Pakistan co-hosted the 1987 Cricket World Cup, but neither ventured beyond the semi-finals. Khan retired from international cricket at the end of the World Cup. In 1988, he was asked to return to the captaincy by the President of Pakistan, General Zia-ul-Haq, and on 18 January, he announced his decision to rejoin the team.[67]\n",
        "\n",
        "Soon after returning to the captaincy, Khan led Pakistan to another winning tour in the West Indies, which he has recounted as \"the last time I really bowled well\".[11] He was declared Man of the Series against West Indies in 1988 when he took 23 wickets in 3 Tests.[67] Khan's career-high as a captain and cricketer came when he led Pakistan to victory in the 1992 Cricket World Cup. Playing with a brittle batting line-up, Khan promoted himself as a batsman to play in the top order along with Javed Miandad, but his contribution as a bowler was minimal. At the age of 39, Khan took the winning last wicket himself.[66][84][85]\n",
        "\n",
        "He holds as a captain the world record for taking most wickets, best bowling strike rate and best bowling average in Test,[86][87] and best bowling figures (8 wickets for 60 runs) in a Test innings,[88] and also most five-wicket hauls (6) in a Test innings in wins.[89]\n",
        "\n",
        "Khan was offered political positions more than a few times during his cricketing career. In 1987, President Zia-ul-Haq offered him a political position in the Pakistan Muslim League (PML) which he politely declined.[123] Khan was also invited by Nawaz Sharif to join his political party.[123] In 1993, Khan was appointed as the ambassador for tourism in the caretaker government of Moeenuddin Ahmad Qureshi and held the portfolio for three months until the government dissolved.[124] In 1994, Khan joined the Jamiat-e-Pasban, a breakaway faction of Jamaat-e-Islami, of Hamid Gul and Muhammad Ali Durrani.[123] On 25 April 1996, Khan founded a political party, Pakistan Tehreek-e-Insaf (PTI).[11][125] He ran for the seat of National Assembly of Pakistan in 1997 Pakistani general election as a candidate of PTI from two constituencies – NA-53, Mianwali and NA-94, Lahore – but was unsuccessful and lost both the seats to candidates of PML (N).[126]\n",
        "\n",
        "Khan supported General Musharraf's 1999 Pakistani coup d'état,[127] believing Musharraf would \"end corruption, clear out the political mafias\".[128] According to Khan, he was Musharraf's choice for prime minister in 2002 but turned down the offer.[129] Khan participated in the October 2002 Pakistani general election that took place across 272 constituencies and was prepared to form a coalition if his party did not get a majority of the vote.[130] He was elected from Mianwali.[131] In the 2002 Pakistani referendum, Khan supported military dictator General Musharraf.[132] He also served as a part of the Standing Committees on Kashmir and Public Accounts.[133] On 6 May 2005, Khan was mentioned in The New Yorker as being the \"most directly responsible\" for drawing attention in the Muslim world to the Newsweek story about the alleged desecration of the Qur'an in a US military prison at the Guantánamo Bay Naval Base in Cuba.[134] In June 2007, Khan faced political opponents in and outside the parliament.[135]\n",
        "\n",
        "On 2 October 2007, as part of the All Parties Democratic Movement, Khan joined 85 other MPs to resign from Parliament in protest of the presidential election scheduled for 6 October, which general Musharraf was contesting without resigning as army chief.[136] On 3 November 2007, Khan was put under house arrest, after president Musharraf declared a state of emergency in Pakistan. Later Khan escaped and went into hiding.[137] He eventually came out of hiding on 14 November to join a student protest at the University of the Punjab.[138] At the rally, Khan was captured by student activists from the Islami Jamiat-e-Talaba and roughly treated.[139] He was arrested during the protest and was sent to the Dera Ghazi Khan jail in the Punjab province where he spent a few days before being released.[140]\n",
        "\n",
        "\n",
        "Khan at the conference \"Rule of Law: The Case of Pakistan\" organised by the Heinrich Böll Foundation in Berlin, 2009\n",
        "On 30 October 2011, Khan addressed more than 100,000 supporters in Lahore, challenging the policies of the government, and referred to his movement as \"not a flood that is coming, but a tsunami.\"[141] A successful public gathering of thousands of supporters was held in Karachi on 25 December 2011.[142] According to a survey conducted by the International Republican Institute (IRI) in 2012, Khan's Pakistan Tehreek-e-Insaf (PTI) topped the list of popular political parties in Pakistan at the national level, with 31% of the vote. The survey, conducted between February 9 and March 8, 2012, found PTI ahead of Pakistan Muslim League-Nawaz (PML-N), which received 27%, and Pakistan Peoples Party (PPP), which garnered 16%. The survey also highlighted PTI's strong performance, particularly in Khyber Pakhtunkhwa (49%) and Balochistan (35%), where the party secured the top spot, though it was second in Punjab with 33%.[143][144]\n",
        "\n",
        "On 6 October 2012, Khan joined a vehicle caravan of protesters from Islamabad to the village of Kotai in Pakistan's South Waziristan region against US drone missile strikes.[145][146] On 23 March 2013, Khan introduced the Naya Pakistan Resolution (New Pakistan) at the start of his election campaign.[147] On 29 April, The Observer termed Khan and his party Pakistan Tehreek-e-Insaf as the main opposition to the Pakistan Muslim League-Nawaz.[148] Between 2011 and 2013, Khan and Nawaz Sharif began to engage each other in a bitter feud. The rivalry between the two leaders grew in late 2011 when Khan addressed his largest crowd at Minar-e-Pakistan in Lahore.[149] From 26 April 2013, in the run up to the elections, both the PML-N and the PTI started to criticise each other.[150]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#kp.get_key_phrases(doc)\n"
      ],
      "metadata": {
        "id": "3VLZVfN8V0Tk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kp.get_key_phrases(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWSQq5xPY40N",
        "outputId": "da2988f8-8ed2-43d6-f4a1-5219fb99572f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pakistan',\n",
              " 'cricket',\n",
              " 'lahore',\n",
              " 'cricket hall of fame',\n",
              " 'pakistan tehreek-e-insaf (pti)',\n",
              " 'national assembly',\n",
              " 'pti',\n",
              " 'coalition government',\n",
              " 'independents',\n",
              " 'balance of payments',\n",
              " 'khan government',\n",
              " 'ehsaas programme',\n",
              " 'plant for pakistan initiative',\n",
              " 'protected areas',\n",
              " 'covid-19 pandemic',\n",
              " 'toshakhana reference case',\n",
              " 'election commission of pakistan',\n",
              " 'assassination attempt',\n",
              " 'islamabad high court',\n",
              " 'riots',\n",
              " 'misusing premiership',\n",
              " 'lettergate',\n",
              " 'islamic marriage law',\n",
              " 'official secret act',\n",
              " '2023 riots',\n",
              " 'clashes',\n",
              " 'khan',\n",
              " 'lahore a (1969–1970)',\n",
              " 'lahore b (1969–1970)',\n",
              " 'lahore greens (1970–1971)',\n",
              " 'lahore (1970–1971)',\n",
              " 'england',\n",
              " 'cricketer',\n",
              " 'batsman',\n",
              " 'bowling',\n",
              " 'odi',\n",
              " 'national team',\n",
              " 'world series',\n",
              " 'fast bowling',\n",
              " 'world record',\n",
              " 'reverse swing bowling',\n",
              " 'fast bowler',\n",
              " 'out and out fast bowler',\n",
              " 'test cricket',\n",
              " 'wicket hauls',\n",
              " 'imran',\n",
              " 'bowling average',\n",
              " 'strike rate',\n",
              " 'test bowling',\n",
              " 'international cricket council',\n",
              " \"all-rounder's triple (securing 3000 runs and 300 wickets)\",\n",
              " 'batting average',\n",
              " 'test batsman',\n",
              " 'cricket world cup',\n",
              " 'batsmanship',\n",
              " 'pakistan cricket',\n",
              " 'odi bowling',\n",
              " 'odi cricket',\n",
              " 'captaincy',\n",
              " 'pakistan cricket team',\n",
              " 'captain',\n",
              " 'sri lanka',\n",
              " 'batting',\n",
              " 'stress fracture',\n",
              " 'shin',\n",
              " 'test series',\n",
              " 'experimental treatment',\n",
              " 'india',\n",
              " 'general zia-ul-haq',\n",
              " 'man of the series',\n",
              " 'batting line-up',\n",
              " 'top order',\n",
              " 'khan took the winning last wicket',\n",
              " 'wickets',\n",
              " 'test innings',\n",
              " 'political positions',\n",
              " 'tourism',\n",
              " 'nawaz sharif',\n",
              " 'jamiat-e-pasban',\n",
              " 'islami',\n",
              " 'political party',\n",
              " 'national assembly of pakistan',\n",
              " 'na-53, mianwali',\n",
              " 'na-94, lahore',\n",
              " \"coup d'état\",\n",
              " 'prime minister',\n",
              " 'musharraf',\n",
              " 'general election',\n",
              " 'coalition',\n",
              " 'military dictatorship',\n",
              " '[134] khan',\n",
              " 'political opponents',\n",
              " 'parliament',\n",
              " 'all parties democratic movement',\n",
              " 'house arrest',\n",
              " 'student protest',\n",
              " 'student activists',\n",
              " 'islami jamiat-e-talaba',\n",
              " 'protesters',\n",
              " 'dera ghazi khan',\n",
              " 'jail',\n",
              " 'rule of law',\n",
              " 'islamic law',\n",
              " 'karachi',\n",
              " 'public gathering',\n",
              " 'supporters',\n",
              " 'political parties',\n",
              " 'popular party',\n",
              " 'pakistani political parties',\n",
              " 'polling',\n",
              " 'performance',\n",
              " 'khyber pakistan',\n",
              " 'protests',\n",
              " 'naya pakistan resolution',\n",
              " 'new pakistan',\n",
              " 'pakistan tehreek-e-insaf',\n",
              " 'pml-n',\n",
              " 'elections']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "source": [
        "!pip install torchvision --force-reinstall --index-url https://download.pytorch.org/whl/cu118"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7LyeIxUfXfiK",
        "outputId": "8b4201d8-449c-4aeb-ea07-1d75d7d8e5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.5 MB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==2.5.1 (from torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp310-cp310-linux_x86_64.whl (838.3 MB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch==2.5.1->torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch==2.5.1->torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting networkx (from torch==2.5.1->torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2 (from torch==2.5.1->torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec (from torch==2.5.1->torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "Collecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "Collecting nvidia-nccl-cu11==2.21.5 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "Collecting nvidia-nvtx-cu11==11.8.86 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==3.1.0 (from torch==2.5.1->torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.1->torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.5.1->torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch==2.5.1->torchvision)\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jinja2, torch, torchvision\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu11\n",
            "    Found existing installation: nvidia-nvtx-cu11 11.8.86\n",
            "    Uninstalling nvidia-nvtx-cu11-11.8.86:\n",
            "      Successfully uninstalled nvidia-nvtx-cu11-11.8.86\n",
            "  Attempting uninstall: nvidia-nccl-cu11\n",
            "    Found existing installation: nvidia-nccl-cu11 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu11-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu11-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu11\n",
            "    Found existing installation: nvidia-cusparse-cu11 11.7.5.86\n",
            "    Uninstalling nvidia-cusparse-cu11-11.7.5.86:\n",
            "      Successfully uninstalled nvidia-cusparse-cu11-11.7.5.86\n",
            "  Attempting uninstall: nvidia-curand-cu11\n",
            "    Found existing installation: nvidia-curand-cu11 10.3.0.86\n",
            "    Uninstalling nvidia-curand-cu11-10.3.0.86:\n",
            "      Successfully uninstalled nvidia-curand-cu11-10.3.0.86\n",
            "  Attempting uninstall: nvidia-cufft-cu11\n",
            "    Found existing installation: nvidia-cufft-cu11 10.9.0.58\n",
            "    Uninstalling nvidia-cufft-cu11-10.9.0.58:\n",
            "      Successfully uninstalled nvidia-cufft-cu11-10.9.0.58\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu11\n",
            "    Found existing installation: nvidia-cuda-runtime-cu11 11.8.89\n",
            "    Uninstalling nvidia-cuda-runtime-cu11-11.8.89:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu11-11.8.89\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu11 11.8.89\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu11-11.8.89:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.8.89\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu11\n",
            "    Found existing installation: nvidia-cuda-cupti-cu11 11.8.87\n",
            "    Uninstalling nvidia-cuda-cupti-cu11-11.8.87:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu11-11.8.87\n",
            "  Attempting uninstall: nvidia-cublas-cu11\n",
            "    Found existing installation: nvidia-cublas-cu11 11.11.3.6\n",
            "    Uninstalling nvidia-cublas-cu11-11.11.3.6:\n",
            "      Successfully uninstalled nvidia-cublas-cu11-11.11.3.6\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.1\n",
            "    Uninstalling filelock-3.16.1:\n",
            "      Successfully uninstalled filelock-3.16.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu11\n",
            "    Found existing installation: nvidia-cusolver-cu11 11.4.1.48\n",
            "    Uninstalling nvidia-cusolver-cu11-11.4.1.48:\n",
            "      Successfully uninstalled nvidia-cusolver-cu11-11.4.1.48\n",
            "  Attempting uninstall: nvidia-cudnn-cu11\n",
            "    Found existing installation: nvidia-cudnn-cu11 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu11-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu11-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu118\n",
            "    Uninstalling torch-2.5.1+cu118:\n",
            "      Successfully uninstalled torch-2.5.1+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu118\n",
            "    Uninstalling torchvision-0.20.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.9.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "ontopic 0.1.0 requires pandas<2.0.0,>=1.5.3, but you have pandas 2.2.3 which is incompatible.\n",
            "ontopic 0.1.0 requires torch<2.0.0,>=1.13.1, but you have torch 2.5.1+cu118 which is incompatible.\n",
            "openai 1.57.4 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "pydantic 2.10.3 requires typing-extensions>=4.12.2, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.13.1 which is incompatible.\n",
            "typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.2.0 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 pillow-10.2.0 sympy-1.13.1 torch-2.5.1+cu118 torchvision-0.20.1+cu118 triton-3.1.0 typing-extensions-4.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "jinja2",
                  "markupsafe",
                  "mpmath",
                  "sympy",
                  "torch",
                  "torchgen",
                  "triton"
                ]
              },
              "id": "f47338f8a7704e6fb1eb49d75e34fc07"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "from keyphrasetransformer import KeyPhraseTransformer"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyF-G8aVXgMX",
        "outputId": "342d7d0c-511e-4149-c27f-8f80f21d9054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip uninstall torchvision"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTuk-FaFXEAH",
        "outputId": "51f52f11-b699-43f5-bbec-2329d9532df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchvision 0.20.1+cu121\n",
            "Uninstalling torchvision-0.20.1+cu121:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision-0.20.1+cu121.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libcudart.7ec1eba6.so.12\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libnvjpeg.f00ca762.so.12\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libwebp.4a54d2c8.so.4\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision.libs/libz.5f199d92.so.1\n",
            "    /usr/local/lib/python3.10/dist-packages/torchvision/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torchvision-0.20.1+cu121\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNEYjZnbXEvZ",
        "outputId": "e1d6087b-d3b0-4859-cb47-3f64095e2360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu118)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch) (11.8.86)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.20.1+cu118\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "goD3G68sWCGN",
        "outputId": "cbadb14d-b0b2-4b62-bda2-32ab58c68f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.1%2Bcu118-cp310-cp310-linux_x86_64.whl (838.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.3/838.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu11\n",
            "    Found existing installation: nvidia-cuda-runtime-cu11 11.7.99\n",
            "    Uninstalling nvidia-cuda-runtime-cu11-11.7.99:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu11-11.7.99\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu11\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu11 11.7.99\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu11-11.7.99:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu11-11.7.99\n",
            "  Attempting uninstall: nvidia-cublas-cu11\n",
            "    Found existing installation: nvidia-cublas-cu11 11.10.3.66\n",
            "    Uninstalling nvidia-cublas-cu11-11.10.3.66:\n",
            "      Successfully uninstalled nvidia-cublas-cu11-11.10.3.66\n",
            "  Attempting uninstall: nvidia-cudnn-cu11\n",
            "    Found existing installation: nvidia-cudnn-cu11 8.5.0.96\n",
            "    Uninstalling nvidia-cudnn-cu11-8.5.0.96:\n",
            "      Successfully uninstalled nvidia-cudnn-cu11-8.5.0.96\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1\n",
            "    Uninstalling torch-1.13.1:\n",
            "      Successfully uninstalled torch-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ontopic 0.1.0 requires pandas<2.0.0,>=1.5.3, but you have pandas 2.2.3 which is incompatible.\n",
            "ontopic 0.1.0 requires torch<2.0.0,>=1.13.1, but you have torch 2.5.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.5.1+cu118 triton-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              },
              "id": "67c091b904134a8594c38c44d04ef99a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jm44zhduV0In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vO_F7bkzVz66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QcG8T8VRVgBf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H-fT20CIVbMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iVa933yHMAkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x-8nxUyQJy5U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yWiqGNYOHfQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "foQnlIf3v3c-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LeKZuuGqvwxg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pQ74XHE1tQVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PvZHARAipgCy"
      }
    }
  ]
}