{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE6Q+Ofd0yKCuCodmvtAwy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fahimku2020/fahimku2020/blob/main/Pynishell_keywordsextraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U90vETreuJx2",
        "outputId": "66dbae80-4b4c-486d-c026-63ed76dbaaca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynutshell\n",
            "  Downloading pynutshell-1.0.2-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pynutshell) (1.26.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pynutshell) (3.4.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from pynutshell) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->pynutshell) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->pynutshell) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->pynutshell) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->pynutshell) (4.67.1)\n",
            "Downloading pynutshell-1.0.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: pynutshell\n",
            "Successfully installed pynutshell-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pynutshell"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whAD6LoyvrYj",
        "outputId": "bb54c27e-2a46-4446-e3ed-74872bed9978"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(sentence):\n",
        "    sentence=str(sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence=sentence.replace('{html}',\"\")\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', sentence)\n",
        "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(rem_num)\n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wv78WzrQyrv4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1RvsQ1a2yre8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nutshell.algorithms.information_retrieval import ClassicalIR\n",
        "from nutshell.model import KeywordExtractor\n",
        "from nutshell.preprocessing.cleaner import NLTKCleaner\n",
        "from nutshell.preprocessing.preprocessor import TextPreProcessor\n",
        "from nutshell.preprocessing.tokenizer import NLTKTokenizer\n",
        "from nutshell.utils import load_corpus\n",
        "\n",
        "corpus = load_corpus('/content/sample_data/A.txt')\n",
        "#print(\"\\n --- Original Text ---\\n\")\n",
        "corpus = preprocess (corpus )\n",
        "#print(corpus)\n",
        "\n",
        "# Text Keyword Extraction\n",
        "preprocessor = TextPreProcessor(NLTKTokenizer(), NLTKCleaner(skip_stemming=True))\n",
        "keyword_extractor = KeywordExtractor(preprocessor, ClassicalIR())\n",
        "keywords = keyword_extractor.extract_keywords(corpus, count=20, raw=False)\n",
        "\n",
        "\n",
        "print(\"\\n --- Keywords ---\\n\")\n",
        "print(keywords)\n"
      ],
      "metadata": {
        "id": "inXFxfAquMfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6094711-1918-41ee-f15d-d8ec66d7ffe9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " --- Keywords ---\n",
            "\n",
            "('bachchan', 'film', 'actor', 'films', 'year', 'best', 'india', 'filmfare', 'award', 'also', 'role', 'first', 'starred', 'time', 'family', 'box', 'office', 'amitabh', 'one', 'indian')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGsxJI8iuMRL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}